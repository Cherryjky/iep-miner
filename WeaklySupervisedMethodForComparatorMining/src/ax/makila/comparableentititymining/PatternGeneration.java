package ax.makila.comparableentititymining;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashSet;
import java.util.List;
import java.util.Set;

import ax.makila.comparableentititymining.postagger.StanfordPosTagger;
import ax.makila.comparableentititymining.sequentialpatterns.patterns.GeneralizedSequence;
import ax.makila.comparableentititymining.sequentialpatterns.patterns.LexicalSequence;
import ax.makila.comparableentititymining.sequentialpatterns.patterns.Pattern;

import com.abahgat.suffixtree.GeneralizedSuffixTree;

@SuppressWarnings("unused")
public class PatternGeneration {
	private static String comparator = MiningIndicativeExtractionPatterns.comparator;
	private static int beta = MiningIndicativeExtractionPatterns.beta;

	public static List<String> mineGoodPatterns(
			List<String> seedComparatorPairs,
			List<String> comparativeQuestionSet) {
		for (String question : comparativeQuestionSet) {
			/*
			 * String surfacePattern = surfaceTextPatternMining(question)
			 */
		}
		Set<Pattern> lexicalPatterns = generateLexicalPatterns(comparativeQuestionSet);
		Set<Pattern> generalizedPatterns = generateGeneralizedPatterns(lexicalPatterns);
		Set<Pattern> specializedPatterns = generateSpecializedPatterns(
				lexicalPatterns, generalizedPatterns);

		return null;
	}

	/**
	 * Lexical patterns indicate sequential patterns consisting of only words
	 * and symbols ($C, #start, and "#end"). They are generated by suffix tree
	 * algorithm with two constraints: A patterns should contain more than one
	 * $C and its frequency in collection should be more than an empirically
	 * determined number beta.
	 * 
	 * @param questions
	 *            The set of questions to generate patterns from
	 * @return A set of lexical patterns
	 */
	public static Set<Pattern> generateLexicalPatterns(List<String> questions) {
		Set<Pattern> lexicalPatterns = new HashSet<Pattern>();
		GeneralizedSuffixTree tree = new GeneralizedSuffixTree();
		String regex = "(^|.*?\\s)\\$c.*?\\s\\$c[^A-Za-z0-9_$].*?$";
		//Add all suffixes to the 
		for(int i = 0; i < questions.size(); i++) {
			tree.put(questions.get(i), i);
		}
		Set<String> candidatePatterns = tree.searchMatchingSuffix(regex);
		// Patterns are only kept if their frequency in the collection is more
		// than an empirically determined number beta
		for(String candidate : candidatePatterns) {
			if(isFrequent(candidate, questions, beta)) {
				LexicalSequence lex = new LexicalSequence(candidate);
				lexicalPatterns.add(lex);
			}
		}
		return lexicalPatterns;
	}
	
	/**
	 * A pattern is only kept if it's frequency in the collection <tt>questionSet</tt>
	 * exceeds a threshold limit <tt>beta</tt>. 
	 * @param pattern The pattern that will be checked with its frequency 
	 * @param questionSet The set of questions that the pattern will match against
	 * @param beta The threshold frequency for the pattern
	 * @return true if the pattern exceeds the threshold, else false.
	 */
	private static boolean isFrequent(String pattern, List<String> questionSet, int beta) {
		int counter = 0;
		for(String question : questionSet) {
			if(question.endsWith(pattern)) {
				counter++;
			}
		}
		return counter > beta;
	}

	/**
	 * A lexical pattern can be too specific. Thus, we generalize lexical
	 * patterns by replacing one or more words/phrases with their POS tags.
	 * 2^(n-1) generalized patterns can be produced from a lexical pattern
	 * containing N words excluding $Cs.
	 * 
	 * @param patterns
	 *            A lexical pattern from which generalized patterns can be
	 *            generated
	 * @return A set of generalized patterns
	 */
	public static Set<Pattern> generateGeneralizedPatterns(
			Set<Pattern> patterns) {
		System.out.println("Start generalization");
		Set<Pattern> generalizedPatterns = new HashSet<Pattern>();
		for (Pattern pattern : patterns) {
			List<List<String>> posTags = StanfordPosTagger
					.getStringTags(pattern.toString());
			List<List<String>> tokenizedWords = StanfordPosTagger
					.tokenizedString(pattern.toString());
			try {
				if (posTags.size() != tokenizedWords.size()) {
					throw new Exception();
				}
			} catch (Exception ex) {
				System.err
						.println("Tags and token length mismatch. Something is funky...");
			}
			for (int i = 0; i < posTags.size(); i++) {
				List<List<String>> combinations = combinations(
						tokenizedWords.get(i), posTags.get(i));
				for (List<String> combo : combinations) {
					String string = StanfordPosTagger.unTokenizeString(combo);
					Pattern seq = new GeneralizedSequence(string);
					generalizedPatterns.add(seq);
				}
			}
		}
		System.out.println("Size = " + generalizedPatterns.size()
				+ "\nEnd generalization!");
		return generalizedPatterns;
	}

	/**
	 * In some cases, a pattern can be too general. For example, although, a
	 * question "ipod or zune" is comparative, the pattern "<$C or $C> is too
	 * general, and there can be many noncomparative questions matching the
	 * pattern, for instance "true or false?". Fir this reason, we perform
	 * pattern specialization by adding POS tags to all comparator slots. For
	 * example, from the lexical pattern, "<$C or $C>" and the question "ipod or
	 * zune", "<$C/NN or $C/NN> will be produced as a specialized pattern.
	 * 
	 * @param lexicalPatterns
	 *            The lexical patterns to be specialized
	 * @param generalPatterns
	 *            The general patterns to be generalized
	 * @return A set of specialized items generated from lexical and general
	 *         patterns.
	 */
	public static Set<Pattern> generateSpecializedPatterns(
			Set<Pattern> lexicalPatterns, Set<Pattern> generalPatterns) {
		List<Pattern> combinedPatterns = new ArrayList<Pattern>(lexicalPatterns);
		combinedPatterns.addAll(generalPatterns);
		Set<Pattern> specializedPatterns = new HashSet<Pattern>();
		for (int i = 0; i < combinedPatterns.size(); i++) {
			Pattern pattern = combinedPatterns.get(i);
			if (pattern.equals(comparator)) {
				String addPos = combinedPatterns.get(i) + "_pos";
				if (pattern.isLexical()) {
					specializedPatterns.add(new LexicalSequence(addPos));
				} else {
					specializedPatterns.add(new GeneralizedSequence(addPos));
				}
			}
		}
		return specializedPatterns;
	}

	/**
	 * Generates all combinations where each element from question is replaced
	 * with the corresponding element from pos.
	 * 
	 * @param question
	 *            Contains the item to be replaced
	 * @param pos
	 *            Contains the POS tags to replace the items
	 * @return Lists containing all possible combinations with question items
	 *         replaced with pos.
	 */

	private static List<List<String>> combinations(List<String> question,
			List<String> pos) {
		List<List<String>> replaced = new ArrayList<List<String>>();
		// int max = (int) Math.pow(2, question.size() - 1);
		int log = (int) Math.ceil(Math.log(question.size() + pos.size())
				/ Math.log(2));
		int max = (int) Math.pow(question.size() + pos.size(), 3);
		int numBits = question.size();
		for (int i = 1; i <= max; i++) {
			String[] questionArray = question.toArray(new String[question
					.size()]);
			String format = "%" + question.size() + "s";
			String bin = String.format(format, Integer.toBinaryString(i))
					.replace(' ', '0');
			char[] binary = bin.toCharArray();
			if (binary.length > question.size()) {
				break;
			}
			for (int j = 0; j < binary.length; j++) {
				if (binary[j] == '1') {
					if (!question.get(j).equals(comparator)) {
						questionArray[j] = pos.get(j);
					}
				}
			}
			replaced.add(Arrays.asList(questionArray));
		}
		return replaced;
	}
	
	

}
